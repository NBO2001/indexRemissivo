{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _isLetter(letter):\n",
    "    # 0 a 47\n",
    "    # 58 a 63\n",
    "    # 91 a 96\n",
    "    # 123 a 126\n",
    "    # 8200,8230\n",
    "    \n",
    "    codeLetter = ord(letter)\n",
    "\n",
    "    return not ( 0 <= codeLetter <= 57 \n",
    "    or 58 <= codeLetter <= 63 \n",
    "    or 91 <= codeLetter <= 96 \n",
    "    or 123 <= codeLetter <= 126 \n",
    "    or 8200 <= codeLetter <= 8230)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(\"9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningWord(word):\n",
    "\n",
    "    i = 0\n",
    "    n = len(word)\n",
    "    \n",
    "    while i < n and not _isLetter(word[i]):\n",
    "        i += 1\n",
    "\n",
    "    j = n\n",
    "    while j > 0 and not _isLetter(word[j-1]):\n",
    "        j -= 1\n",
    "    \n",
    " \n",
    "    word = word[i:j]\n",
    "    \n",
    "    return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(palavra, doc):\n",
    "    # palavra : total de palavras que aparceu no doc\n",
    "    # doc : numero total de palavras do doc\n",
    "    return palavra/doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_containing(palavra, docs):\n",
    "    # retorna o numero de documento que tem a palvra\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(qntWords, docs):\n",
    "    # Palavra: total de documentos que tem a palavra\n",
    "    # docs: total de documentos\n",
    "    h= docs/(qntWords if qntWords > 0 else 1)\n",
    "    return math.log2(h)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(palavra, doc,qntWords, docs):\n",
    "    return tf(palavra, doc) * idf(qntWords, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStopWords():\n",
    "    file_ = open(\"../data/stopwords_br.txt\")\n",
    "    wordsStop = []\n",
    "    linhas = file_.readlines()\n",
    "\n",
    "    for line in linhas:\n",
    "        wordsStop.append(cleaningWord(line))\n",
    "\n",
    "    return wordsStop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(word,stopW):\n",
    "    return not cleaningWord(word) in stopW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotWords(file,stopWords,doc, start, end):\n",
    "    wordsInDoc = {}\n",
    "    totWord = 0\n",
    "\n",
    "    for idxLine in range(start, end+1):\n",
    "        \n",
    "        wos = [ cleaningWord(x) for x in file[idxLine].split(\" \") if validate(x,stopWords)]\n",
    "\n",
    "        for wo in wos:\n",
    "            totWord += 1\n",
    "            if not wo in wordsInDoc.keys():\n",
    "                wordsInDoc[wo] = 1\n",
    "            else:\n",
    "                wordsInDoc[wo] += 1\n",
    "    return wordsInDoc, totWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mappingPages(file):\n",
    "    totLines = len(file)\n",
    "\n",
    "    pages = {}\n",
    "    startPage = 0\n",
    "    endPage = 0\n",
    "    ultPage = 1\n",
    "    i = 1\n",
    "\n",
    "    while i < totLines:\n",
    "\n",
    "        subStr = file[i][:2]\n",
    "\n",
    "        if (subStr == \"PA\"):\n",
    "            endPage = i-1\n",
    "            pages[ultPage] = {\n",
    "                \"start\":startPage,\n",
    "                \"end\": endPage\n",
    "            }\n",
    "\n",
    "            startPage = i\n",
    "            ultPage += 1\n",
    "\n",
    "        i+=1\n",
    "\n",
    "\n",
    "    endPage = i-1\n",
    "    pages[ultPage] = {\n",
    "        \"start\":startPage,\n",
    "        \"end\": endPage\n",
    "    }\n",
    "\n",
    "    return pages\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprareTable(dicResult, totDocs, totWords):\n",
    "    \n",
    "    words = []\n",
    "    recurrences = []\n",
    "    pontuation = []\n",
    "    pagesOc = []\n",
    "\n",
    "    for wd in dicResult:\n",
    "        words.append(wd)\n",
    "        recurrences.append(dicResult[wd][\"totRecorences\"])\n",
    "\n",
    "        pont = 0\n",
    "        stringTmp = \"\"\n",
    "        for page in dicResult[wd][\"pages\"]:\n",
    "            tmp = tfidf(dicResult[wd][\"pages\"][page][\"recorrences\"], dicResult[wd][\"pages\"][page][\"totWord\"], dicResult[wd][\"totPages\"], totDocs)\n",
    "            pont += tmp\n",
    "            stringTmp = f'{stringTmp} -> {page}: {dicResult[wd][\"pages\"][page][\"totWord\"]}'\n",
    "\n",
    "        toP = dicResult[wd][\"totPages\"] if dicResult[wd][\"totPages\"] > 0 else 1\n",
    "\n",
    "        pont = pont/toP\n",
    "\n",
    "        pontuation.append( pont )\n",
    "        pagesOc.append( stringTmp )\n",
    "\n",
    "    \n",
    "    d = {'palavra': words, 'rec': recurrences, \"pont\": pontuation}\n",
    "        \n",
    "    return pd.DataFrame(data=d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages: 264\n"
     ]
    }
   ],
   "source": [
    "# file_ = open(\"../data/Paralelismo.base\")\n",
    "# ffile_ = open(\"../data/Guarani.base\")\n",
    "file_ = open(\"../data/Aventuras.base\")\n",
    "lines = file_.readlines()\n",
    "\n",
    "pages = mappingPages(lines)\n",
    "print(f\"Pages: {len(pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "wordsResul = {}\n",
    "\n",
    "wordCont = 0\n",
    "\n",
    "stopWords = loadStopWords()\n",
    "\n",
    "for page in pages:\n",
    "\n",
    "    start = pages[page][\"start\"]\n",
    "    end = pages[page][\"end\"]\n",
    "\n",
    "    words, totWord = getTotWords(lines,stopWords, page, start, end)\n",
    "    for wd in words:\n",
    "        if len(wd) == 0:\n",
    "            continue\n",
    "\n",
    "        wordCont += 1\n",
    "            \n",
    "        if not wd in wordsResul.keys():\n",
    "            wordsResul[wd] = {\n",
    "                \"pages\":{\n",
    "                    page:{\n",
    "                        \"recorrences\": words[wd],\n",
    "                        \"totWord\": totWord\n",
    "                    }\n",
    "                },\n",
    "                \"totPages\": 1,\n",
    "                \"totRecorences\": words[wd]\n",
    "            }\n",
    "        else:\n",
    "            wordsResul[wd][\"pages\"][page] = {\n",
    "                \"recorrences\": words[wd],\n",
    "                \"totWord\": totWord\n",
    "            }\n",
    "            wordsResul[wd][\"totPages\"] += 1\n",
    "            wordsResul[wd][\"totRecorences\"] += words[wd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        palavra  rec      pont\n",
      "4816      sonho    5  0.132746\n",
      "8122   exéquias    5  0.132746\n",
      "6678      vinde    5  0.129748\n",
      "10705    cótica    5  0.127689\n",
      "11255  compadre   11  0.125992\n",
      "...         ...  ...       ...\n",
      "485       disse  151  0.005096\n",
      "431        pois  173  0.005076\n",
      "1058      mesmo  167  0.005022\n",
      "567          só  235  0.004285\n",
      "0            pa  264  0.000000\n",
      "\n",
      "[11581 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "table = preprareTable(wordsResul, len(pages), wordCont)\n",
    "\n",
    "# table = table.loc[table[\"rec\"] > 1]\n",
    "# table = table.loc[table[\"rec\"] <= 5]\n",
    "table = table.sort_values(by=\"pont\", ascending=False)\n",
    "print(table)\n",
    "\n",
    "table.to_csv(\"Paralelismo.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerCase(string):\n",
    "\n",
    "    size = len(string)\n",
    "\n",
    "    for i in range(size):\n",
    "\n",
    "        if ord(string[i]) >= 65 and ord(string[i]) <= 90:\n",
    "            string[i] = chr(ord(string[i]) + 32)\n",
    "        elif(ord(string[i]) >= 193 and ord(string[i]) <= 214):\n",
    "            string[i] = chr(ord(string[i]) + 32)\n",
    "        \n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/natanael/indexRemissivo/tablePy/app2.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/natanael/indexRemissivo/tablePy/app2.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lowerCase(\u001b[39m\"\u001b[39;49m\u001b[39mVISÃo\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/home/natanael/indexRemissivo/tablePy/app2.ipynb Cell 19\u001b[0m in \u001b[0;36mlowerCase\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/natanael/indexRemissivo/tablePy/app2.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(size):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/natanael/indexRemissivo/tablePy/app2.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mord\u001b[39m(string[i]) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m65\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mord\u001b[39m(string[i]) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m90\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/natanael/indexRemissivo/tablePy/app2.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         string[i] \u001b[39m=\u001b[39m \u001b[39mchr\u001b[39m(\u001b[39mord\u001b[39m(string[i]) \u001b[39m+\u001b[39m \u001b[39m32\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/natanael/indexRemissivo/tablePy/app2.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39melif\u001b[39;00m(\u001b[39mord\u001b[39m(string[i]) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m193\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mord\u001b[39m(string[i]) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m214\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/natanael/indexRemissivo/tablePy/app2.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         string[i] \u001b[39m=\u001b[39m \u001b[39mchr\u001b[39m(\u001b[39mord\u001b[39m(string[i]) \u001b[39m+\u001b[39m \u001b[39m32\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "lowerCase(\"VISÃo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natanael'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"Natanael\"\n",
    "\n",
    "dec = {\n",
    "    \"name\":name\n",
    "}\n",
    "\n",
    "dec[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natanael'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"Porra\"\n",
    "dec[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porra\n"
     ]
    }
   ],
   "source": [
    "print(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04dcb3f6a367c728cd23f66085c9c7d5d2b5cfc39fd5eebfcaa944146d36fa18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
